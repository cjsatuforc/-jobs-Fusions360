# -jobs-Fusions360

[Task 1 : find time]
  
  以川普的 wiki 為例 (https://zh.m.wikipedia.org/zh-hant/%E5%94%90%E7%B4%8D%C2%B7%E5%B7%9D%E6%99%AE)
  
  1. 首先，經觀察後發現 wiki 網頁大致分為三部分：
  
    (1) para : 內文各個段落
    (2) vcard : 網頁右方，個人簡介的表格
    (3) ref : 最後的資料來源
    
    故本程式分別爬取這三類文字資料，並標示出段落，方便之後尋找。
    
  2. 時間大致分為三類來處理：
  
    (1) 含中文的，例如：'2017年4月26日'、'4月26日'....
    (2) 含英文月份的，例如：'March 5, 2016'、'March, 2016'....
    (3) 純數字與符號，例如：'2016-3-5', '2016.3.5', '2016/3/5'....
    
    透過模糊字串的處理方式，來增加辨識正確率。此外，再透過簡單的判斷式，來檢查是否有無效值(ex: 3月68號)
    
  3. Output
  
    最後將輸出一個dataframe，包含時間出現的地點、段落、原始時間格式、國際標準格式、國際標準格式(含NA)，範例如下
    
    
              [type]         [txt]               [raw_date]    [POSIXt_date]   [POSIXt_date_NA]
         1     para        今天是8月2號             8月2號          08-02           NA-08-02
         2     para    Today is Aug 2, 2017      Aug 2, 2017     2017-08-02      2017-08-02
              
  4. 中階：
  
    (1) 這部分比較麻煩，因為不同語言有不同的專有名詞(例如：中秋節、Easter...)
    (2) 我目前想到的方式有增加辭庫、或是透過字串處理的方式 (偵測到"節"結尾且三個字元的字詞)，但顯然不會是最好的方法。
    
  5. 挑戰：
  
    (1) 首先，要先讓電腦了解"昨日、隔日"的意義。
    (2) if (出現這類字詞), then (date = 前方第一個日期減 86400 秒)
             
[Task 2 : find name]

  以川普的 wiki 為例 (https://zh.m.wikipedia.org/zh-hant/%E5%94%90%E7%B4%8D%C2%B7%E5%B7%9D%E6%99%AE)
  
  1. 程式為三部分：
  
    [0] 直接抓取 wiki 上的所有文字資料
    [1] 進行斷詞，並取出人名 (nr)
    [2] 整理成 freq table
    
    
  2. 提高正確率：
  
    (1) 在 First try 時，發現有許多斷詞錯誤或文法標籤錯誤，例如：'上周四', '小丘', '小姐', '小鎮' 被視為人名。
    (2) 在 Second try 時，透過新增詞庫(new_user_word)，來更新詞庫與修改標籤，以斷詞準確率及人名辨識正確率。
    
    
  3. 中階 & 挑戰：
  
    (1) 透過新增詞庫的方式來解決。但這個方法缺點很明顯，必須case by case。
    (2) 需要透過語意分析的方式，例如：用潛在語意分析來處理一字多義...等問題。
 
